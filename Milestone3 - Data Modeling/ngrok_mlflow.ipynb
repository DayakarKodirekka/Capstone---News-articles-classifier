{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ngrok_mlflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4dmyM-dzang",
        "outputId": "580f864c-5abf-4f08-bead-8143de230347"
      },
      "source": [
        "!pip install mlflow --quiet\n",
        "import mlflow\n",
        "print(mlflow.__version__)\n",
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 14.6 MB 117 kB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 53.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 146 kB 55.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 27.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 58.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "1.20.2\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 42 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 52.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=8606423adb86e018fa5cc9a7edc63c0010cd8e3eea08b5887fcf0ef1e0b42417\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-4QcFBMzkbq",
        "outputId": "bbd24d41-ffd2-43b2-af18-7f752cbdc42a"
      },
      "source": [
        "!pip install pyngrok --quiet\n",
        "from pyngrok import ngrok\n",
        "from getpass import getpass\n",
        "# Terminate open tunnels if any exist\n",
        "# ngrok.kill()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 29.8 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 92 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 143 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 153 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 163 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 174 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 184 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 194 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 204 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 215 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 225 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 235 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 245 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 266 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 276 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 286 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 296 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 307 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 317 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 337 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 348 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 358 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 368 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 378 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 389 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 399 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 409 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 430 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 440 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 450 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 460 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 471 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 481 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 491 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 501 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 512 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 522 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 532 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 542 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 552 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 563 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 573 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 583 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 593 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 604 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 614 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 624 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 634 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 645 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 655 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 665 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 675 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 686 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 696 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 706 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 716 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 727 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 737 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 745 kB 10.2 MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1E-XIVx1kId"
      },
      "source": [
        "import pandas as pd\n",
        "import pyspark\n",
        "import mlflow\n",
        "import mlflow.spark\n",
        "\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import HashingTF, Tokenizer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAnIX6y1zbw-"
      },
      "source": [
        "with mlflow.start_run(run_name=\"MLflow on Colab\"):\n",
        "  mlflow.log_metric(\"m1\", 2.0)\n",
        "  mlflow.log_param(\"p1\", \"mlflow-colab\")\n",
        "# run tracking UI in the background\n",
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSOJwUUq1pdj"
      },
      "source": [
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql.session import SparkSession\n",
        "sc = SparkContext('local')\n",
        "spark = SparkSession(sc)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WdEDodakmor"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYz4wTpu1sQ5"
      },
      "source": [
        "df = pd.read_csv('news_final (1).csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFGzZBFglKHA"
      },
      "source": [
        "df = df.drop('author', axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnKs65aX1ukz"
      },
      "source": [
        "train_df = spark.createDataFrame(df)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPYk9-6i0Q0S",
        "outputId": "c8fc97a1-ecdc-41ec-f59c-944210c02c38"
      },
      "source": [
        "# Start a new MLflow run\n",
        "import mlflow.mleap\n",
        "with mlflow.start_run(run_name=\"Capstone_News\") as run:\n",
        "    # regular expression tokenizer\n",
        "  regexTokenizer = RegexTokenizer(inputCol=\"summary\", outputCol=\"words\", pattern=\"\\\\W\")\n",
        "  # stop words\n",
        "  add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\"] \n",
        "  stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n",
        "  # bag of words count\n",
        "  countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
        "  label_stringIdx = StringIndexer(inputCol = \"topic\", outputCol = \"label\")\n",
        "  pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n",
        "  # Fit the pipeline to training documents.\n",
        "  pipelineFit = pipeline.fit(train_df)\n",
        "  dataset = pipelineFit.transform(train_df)\n",
        "  dataset.show(5)\n",
        "  # set seed for reproducibility\n",
        "  (trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
        "  print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "  print(\"Test Dataset Count: \" + str(testData.count()))\n",
        "  lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
        "  lrModel = lr.fit(trainingData)\n",
        "  predictions = lrModel.transform(testData)\n",
        "  predictions.filter(predictions['prediction'] == 0) \\\n",
        "      .select(\"summary\",\"topic\",\"probability\",\"label\",\"prediction\") \\\n",
        "      .orderBy(\"probability\", ascending=False) \\\n",
        "      .show(n = 10, truncate = 30)\n",
        "\n",
        "  evaluator_lr_cv = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "  evaluator_lr_cv.evaluate(predictions)\n",
        "# pred=lr.predict(test_x)\n",
        "  # (rmse, mae, r2) = eval_metrics(prediction,label_stringIdx)\n",
        "  #  mlflow.log_metric(\"rmse\", rmse)\n",
        "  #  mlflow.log_metric(\"r2\", r2)\n",
        "  #  mlflow.log_metric(\"mae\", mae)\n",
        "  # mlflow.log_param(\"max_iter\", param['max_iter'])\n",
        "  # mlflow.log_param(\"penalty\", param['penalty'])\n",
        "  # mlflow.log_param(\"solver\", param['solver'])\n",
        "    \n",
        "    #logging data which we used for this model\n",
        "  # mlflow.log_artifact(\"96fa465011b74bf88df4babd69ad1401\")\n",
        "\n",
        "  # Log the model within the MLflow run\n",
        "  # mlflow.spark.log_model(spark_model=lrModel, sample_input=df, artifact_path=\"lrModel\")\n",
        "  mlflow.spark.save_model(lrModel, \"spark-model\")\n",
        "# mlflow.spark.load_model(path, run_id=None, dfs_tmpdir='/tmp/mlflow'\n",
        "# run tracking UI in the background\n",
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+--------------------+--------------------+-------------------+--------+--------------------+--------------------+--------------------+-----+\n",
            "|Unnamed: 0|               title|             summary|                link|           pub_date|   topic|               words|            filtered|            features|label|\n",
            "+----------+--------------------+--------------------+--------------------+-------------------+--------+--------------------+--------------------+--------------------+-----+\n",
            "|         0|The difference be...|Business Analysis...|https://medium.co...|2021-10-16 06:09:58|    news|[business, analys...|[business, analys...|(304,[0,1,2,3,6,8...|  0.0|\n",
            "|         1|Writing Off the E...|Starting a busine...|https://www.theba...|2021-10-22 20:46:00|    news|[starting, a, bus...|[starting, a, bus...|(304,[0,1,2,4,8,1...|  0.0|\n",
            "|         2|How To Register a...|Finding a busines...|https://blog.hubs...|2021-10-19 11:00:00|business|[finding, a, busi...|[finding, a, busi...|(304,[0,1,2,4,5,8...|  1.0|\n",
            "|         3|PDF Download*% Es...|Upcoming SlideSha...|https://www.slide...|2021-10-22 03:32:36|    news|[upcoming, slides...|[upcoming, slides...|(304,[0,1,2,5,6,1...|  0.0|\n",
            "|         4|NBA, LegalZoom Te...|The National Bask...|https://news.yaho...|2021-10-16 00:10:43|    news|[the, national, b...|[national, basket...|(304,[0,1,2,3,4,5...|  0.0|\n",
            "+----------+--------------------+--------------------+--------------------+-------------------+--------+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "Training Dataset Count: 89\n",
            "Test Dataset Count: 36\n",
            "+------------------------------+------+------------------------------+-----+----------+\n",
            "|                       summary| topic|                   probability|label|prediction|\n",
            "+------------------------------+------+------------------------------+-----+----------+\n",
            "|Dublin, Oct. 20, 2021 (GLOB...|  news|[0.9891860850294178,0.00234...|  0.0|       0.0|\n",
            "|New York, NY, Oct. 20, 2021...|  news|[0.979586936258292,0.004258...|  0.0|       0.0|\n",
            "|Home News Sports Living Art...|  news|[0.9788038850670272,0.00547...|  0.0|       0.0|\n",
            "|Home News Sports Living Art...|  news|[0.9788038850670272,0.00547...|  0.0|       0.0|\n",
            "|Home News Sports Living Art...|  news|[0.9788038850670272,0.00547...|  0.0|       0.0|\n",
            "|Home News Sports Living Art...|  news|[0.9781883132175464,0.00559...|  0.0|       0.0|\n",
            "|Upcoming SlideShare What to...|  news|[0.9518927404604928,0.01465...|  0.0|       0.0|\n",
            "|BeLive Technology appoints ...|gaming|[0.9444878753024972,0.01213...|  4.0|       0.0|\n",
            "|Upcoming SlideShare What to...|  news|[0.9248662643557746,0.02506...|  0.0|       0.0|\n",
            "|Upcoming SlideShare What to...|  news|[0.9248662643557746,0.02506...|  0.0|       0.0|\n",
            "+------------------------------+------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyE2YDp9zrpl",
        "outputId": "183b489b-af0b-44ba-d18d-ffab0404478e"
      },
      "source": [
        "# Enter your auth token when the code is running\n",
        "# 1zt2ytXyrAhXfMSFbjJBkqbCmD6_5FEDkfjsNCearfyE3i2JD\n",
        "NGROK_AUTH_TOKEN = getpass('Enter the ngrok authtoken:')\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the ngrok authtoken:··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t=2021-10-23T09:59:42+0000 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking UI: https://b624-35-233-249-132.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZEcjFuh2aYI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}